{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Canonical tSNE Analysis\"\nauthor: \"Ilaria Bonavita\"\ndate: \"18 January 2017\"\noutput:\n  md_document:\n    variant: markdown_github\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n## 3D to 2D Example\n\nWe try the algorithm on a toy example.\nFirst we generate two datasets. We consider here the problem of learning a 2-dimensional projections matrices from a 3-dimensional dataset.\n\n```{r}\n# dimension of the input features space\nq <- 3\n# dimension of the output transformed features\nd <- 2\n# Overal number of examples (train+test)\nN <- 100\n### Generate data \nMaxAngle <- 4*pi\nMinRadius <-0.3\nMaxRadius <- 8\nsx <- 0.5\nsy <- 0.5\nset.seed(1244)\nt <- seq(0, MaxAngle, length.out = N)\nr <- seq(MinRadius, MaxRadius, length.out = N) + 2*runif(N)\n#### generate X, the noise can be added!\nset.seed(123)\nX <- cbind(r*cos(t+0*rnorm(N)*0.05),r*sin(t+0*rnorm(N)*0.05),rnorm(N))\n#### generate Y, the noise can be added!\nY <- cbind(t+0*rnorm(N)*1, 2*rnorm(N),rnorm(N))\n```\n\nWe plot only the first two dimensions (the third dimension is basically noise)\n\n```{r, echo=FALSE}\npar(mfrow = c(1, 2))\n  col_b2y <- colorRampPalette(c(\"blue\", \"cyan\", \"orange\", \"yellow\"))\n  plot(X, pch = 19, col = col_b2y(N), \n       main = \"View of X\", xlab = \"X.1\", ylab = \"X.2\", xlim = range(X[,1]*1.1), ylim = range(X[,2]*1.1))\n  plot(Y, pch = 19, col = col_b2y(N), \n       main = \"View of Y\", xlab = \"Y.1\", ylab = \"Y.2\", xlim = range(Y[,1]*1.1), ylim = range(Y[,2]*1.3))\n```\n\nAnd we can plot the coordinates of X vs Y\n\n```{r, echo=FALSE}\n par(mfrow = c(1, 2))\n  col_b2y <- colorRampPalette(c(\"blue\", \"cyan\", \"orange\", \"yellow\"))\n  plot(X[,1], Y[,1] ,pch = 19, col = col_b2y(N), \n       main = \"X1 vs Y1\", xlab = \"X.1\", ylab = \"Y.1\", xlim = range(X[,1]*1.1), ylim = range(Y[,1]*1.1))\n  plot(X[,2], Y[,2] ,pch = 19, col = col_b2y(N), \n       main = \"X2 vs Y2\", xlab = \"X.2\", ylab = \"Y.2\", xlim = range(X[,2]*1.1), ylim = range(Y[,2]*1.1))\n```\n\nWe define a matrix of the distance between Xi and Xj (Yi and Yj) for all the possible combination of elements in X (Y)\n\n```{r}\nX.pairs <- combn(seq(1:nrow(X)),2)\nY.pairs <- combn(seq(1:nrow(Y)),2)\n\n# Each row correspond to a pair (i,j), columns are the coordinates of the distance xi-xj\nX.dist <- X[X.pairs[1,],] - X[X.pairs[2,],]\nY.dist <- Y[Y.pairs[1,],] - Y[Y.pairs[2,],]\n```\nThen we pass the distance matrices to a batch gradient descent algorithm to find the optimal projection matrices for dataset X and dataset Y\n\n```\nbatch.grad.desc.fun(X.dist, Y.dist, N, dim.out=2,\n                    gamma.list= c(0.06,0.05),\n                    nexper = 1,\n                    maxiter= 200,\n                    wd.path= '/Users/ilaria_bonavita/My_project/tSNEcca',\n                    ...\n                    )\n``` \n\nThe function returns the two optimal matrices W.opt and Z.opt. We then map the 3-d points into the 2-d space \n\n\n```{r, echo=FALSE}\nmat.path <- '/Users/ilaria_bonavita/My_project/tSNEcca/N100_in3_out2_rnd/exp_1gamma0.05/'\nW.opt <- readRDS(paste0(mat.path,'Wout.RDS'))\nZ.opt <- readRDS(paste0(mat.path,'Zout.RDS'))\n```\n```{r}\n  XW <- W.opt%*%t(X)\n  YZ <- Z.opt%*%t(Y)\n```\n\n```{r, echo=FALSE}\npar(mfrow = c(1, 2))\n  col_b2y <- colorRampPalette(c(\"blue\", \"cyan\", \"orange\", \"yellow\"))\n  plot(t(XW), pch = 19, col = col_b2y(N), \n       main = \"View of X\", xlab = \"X.1\", ylab = \"X.2\", xlim = range(XW[1,]*1.1), ylim = range(XW[2,]*1.1))\n  plot(t(YZ), pch = 19, col = col_b2y(N), \n       main = \"View of Y\", xlab = \"Y.1\", ylab = \"Y.2\", xlim = range(YZ[1,]*1.1), ylim = range(YZ[2,]*1.3))\n\n```\n\nWe can also plot the coordinates of X vs Y to see what's going on\n\n```{r, echo=FALSE}\npar(mfrow = c(1, 2))\n  col_b2y <- colorRampPalette(c(\"blue\", \"cyan\", \"orange\", \"yellow\"))\n  plot(XW[1,], YZ[1,] ,pch = 19, col = col_b2y(N), \n       main = \"View of X1 vs Y1\", xlab = \"X.1\", ylab = \"Y.1\", xlim = range(XW[1,]*1.1), ylim = range(YZ[1,]*1.1))\n  plot(XW[2,],YZ[2,], pch = 19, col = col_b2y(N), \n       main = \"View of X2 vs Y2\", xlab = \"X.2\", ylab = \"Y.2\", xlim = range(XW[2,]*1.1), ylim = range(YZ[2,]*1.3))\n```\n\n## Comparison with other Canonical Correlation Analysis methods\n\nIf we apply a simple CCA, we obtain the following results\n\n```{r, echo=F,message=F,warning=F}\n# Perform CCA\n\ncca_res  <- cancor(X,Y)\n\nXWcca <- X %*% cca_res$xcoef\nYZcca <- Y %*% cca_res$ycoef\n\npar(mfrow = c(1, 2))\ncol_b2y <- colorRampPalette(c(\"blue\", \"cyan\", \"orange\", \"yellow\"))\nplot(XWcca, pch = 19, col = col_b2y(N), \n     main = \"View of X\", xlab = \"X.1\", ylab = \"X.2\", xlim = range(XWcca[,1]*1.1), ylim = range(XWcca[,2]*1.1))\nplot(YZcca, pch = 19, col = col_b2y(N), \n     main = \"View of Y\", xlab = \"Y.1\", ylab = \"Y.2\", xlim = range(YZcca[,1]*1.1), ylim = range(YZcca[,2]*1.3))\n\npar(mfrow = c(1, 2))\ncol_b2y <- colorRampPalette(c(\"blue\", \"cyan\", \"orange\", \"yellow\"))\nplot(XWcca[,1], YZcca[,1] ,pch = 19, col = col_b2y(N), \n     main = \"View of X1 vs Y1\", xlab = \"X.1\", ylab = \"Y.1\", xlim = range(XWcca[,1]*1.1), ylim = range(YZcca[,1]*1.1))\nplot(XWcca[,2],YZcca[,2], pch = 19, col = col_b2y(N), \n     main = \"View of X2 vs Y2\", xlab = \"X.2\", ylab = \"Y.2\", xlim = range(XWcca[,2]*1.1), ylim = range(YZcca[,2]*1.3))\n\n```\n\nThis is what we obtain if we transform the input dataset with Nonparametric CCA (NCCA) with Gaussian KDE (1d)\n\n```{r, echo=FALSE,message=FALSE, warning=FALSE}\n\nrequire(FNN)\nrequire(Matrix)\nrequire(irlba)\nsource('./ncca.R')\nncca_res <- ncca(X,Y, d = 2, hx = 0.75, hy = 0.75, nx=5, ny=5, verbose = F)\n\nX_proj_paired <- ncca_res$X_new\nY_proj_paired <- ncca_res$Y_new\n\npar(mfrow = c(1, 2))\ncol_b2y <- colorRampPalette(c(\"blue\", \"cyan\", \"orange\", \"yellow\"))\nplot(X_proj_paired, pch = 19, col = col_b2y(N), \n     main = \"View of X\", xlab = \"X.1\", ylab = \"X.2\", xlim = range(X_proj_paired[,1]*1.1), ylim = range(X_proj_paired[,2]*1.1))\nplot(Y_proj_paired, pch = 19, col = col_b2y(N), \n     main = \"View of Y\", xlab = \"Y.1\", ylab = \"Y.2\", xlim = range(Y_proj_paired[,1]*1.1), ylim = range(Y_proj_paired[,2]*1.3))\n\npar(mfrow = c(1, 2))\ncol_b2y <- colorRampPalette(c(\"blue\", \"cyan\", \"orange\", \"yellow\"))\nplot(X_proj_paired[,1], Y_proj_paired[,1] ,pch = 19, col = col_b2y(N), \n     main = \"Projections X1 vs Y1\", xlab = \"X.1\", ylab = \"Y.1\", xlim = range(X_proj_paired[,1]*1.1), ylim = range(Y_proj_paired[,1]*1.1))\nplot(X_proj_paired[,2],Y_proj_paired[,2], pch = 19, col = col_b2y(N), \n     main = \"Projections X2 vs Y2\", xlab = \"X.2\", ylab = \"Y.2\", xlim = range(X_proj_paired[,2]*1.1), ylim = range(Y_proj_paired[,2]*1.3))\n\n```\n\nWe also applied Kernel CCA (KCCA). The plot shows the dataset X against Y projected in the kernel latent space\n\n```{r, echo=FALSE,message=FALSE, warning=FALSE}\n# Perform KCCA\nlibrary(kernlab)\nlibrary(geigen)\nsource('./kerncca.R')\n\nkerncca_res <- kerncca(X,Y)\n\nplot(kerncca_res$latent1,kerncca_res$latent2, pch = 19, col = col_b2y(N), \n     main = \"Projections X vs Y\", xlab = \"X.2\", ylab = \"Y.2\", xlim = range(kerncca_res$latent1*1.1), ylim = range(kerncca_res$latent2*1.3))\n\n```\n\n\n\n\n\n",
    "created" : 1484758760765.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2842594428",
    "id" : "7FA800EC",
    "lastKnownWriteTime" : 1484838980,
    "last_content_update" : 1484838980234,
    "path" : "~/My_project/tSNEcca/CtsneA.Rmd",
    "project_path" : "CtsneA.Rmd",
    "properties" : {
        "source_window_id" : "wjz5bd64kwwtb",
        "tempName" : "Untitled1"
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}